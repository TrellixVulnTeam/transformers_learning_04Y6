{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5699538c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T05:18:40.555543Z",
     "start_time": "2021-06-20T04:32:51.844Z"
    }
   },
   "outputs": [],
   "source": [
    "# 参考网址\n",
    "https://github.com/blmoistawinde/hello_world/blob/master/huggingface_classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b634ffdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T04:01:07.304182Z",
     "start_time": "2021-06-20T04:01:07.300381Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"  # 在此我指定使用2号GPU，可根据需要调整\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15337ede",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T04:01:15.243238Z",
     "start_time": "2021-06-20T04:01:07.958683Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/Users/lhj/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/Users/lhj/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/Users/lhj/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['label', 'text'],\n",
      "    num_rows: 40000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['label', 'text'],\n",
      "    num_rows: 10000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['label', 'text'],\n",
      "    num_rows: 7600\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"ag_news\", split=\"train[:40000]\")\n",
    "dev_dataset = load_dataset(\"ag_news\", split=\"train[40000:50000]\")\n",
    "test_dataset = load_dataset(\"ag_news\", split=\"test\")\n",
    "print(train_dataset)\n",
    "print(dev_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99eabdd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T04:01:18.154417Z",
     "start_time": "2021-06-20T04:01:18.150151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': ClassLabel(num_classes=4, names=['World', 'Sports', 'Business', 'Sci/Tech'], names_file=None, id=None),\n",
       " 'text': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 原始数据集包含text和label两个字段\n",
    "train_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e386357f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T04:01:19.365160Z",
     "start_time": "2021-06-20T04:01:19.354723Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/lhj/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-a71af80ff604ecf2.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 2,\n",
       " 'labels': 2,\n",
       " 'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 由于bert模型期望得到的标签的字段为labels而原始数据集中的名字是label，所以做一下调整。\n",
    "# 下面的代码把label字段复制到labels。\n",
    "train_dataset = train_dataset.map(lambda examples: {'labels': examples['label']}, batched=True)\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a707dcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T04:01:20.519760Z",
     "start_time": "2021-06-20T04:01:20.508577Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/lhj/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-bf0d4122b89150d7.arrow\n",
      "Loading cached processed dataset at /Users/lhj/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-6e6e36e6400f3e4c.arrow\n"
     ]
    }
   ],
   "source": [
    "dev_dataset = dev_dataset.map(lambda examples: {'labels': examples['label']}, batched=True)\n",
    "test_dataset = test_dataset.map(lambda examples: {'labels': examples['label']}, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d50402de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T04:01:31.986042Z",
     "start_time": "2021-06-20T04:01:21.666064Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 加载模型，tokenizer，并预处理数据\n",
    "model_id = 'prajjwal1/bert-tiny'\n",
    "# note that we need to specify the number of classes for this task\n",
    "# we can directly use the metadata (num_classes) stored in the dataset\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, \n",
    "            num_labels=train_dataset.features[\"label\"].num_classes)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1608ff78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T04:01:45.615364Z",
     "start_time": "2021-06-20T04:01:44.570115Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/lhj/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-43f38ac5550c93ca.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d894c84c76e54e308b579a20243da418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/lhj/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-aa0d456a24691c94.arrow\n"
     ]
    }
   ],
   "source": [
    "# bert的方法对数据集做分词预处理，把所有序列补充或截断到256个token\n",
    "MAX_LENGTH = 256\n",
    "train_dataset = train_dataset.map(lambda e: tokenizer(e['text'], truncation=True, padding='max_length', max_length=MAX_LENGTH), batched=True)\n",
    "dev_dataset = dev_dataset.map(lambda e: tokenizer(e['text'], truncation=True, padding='max_length', max_length=MAX_LENGTH), batched=True)\n",
    "test_dataset = test_dataset.map(lambda e: tokenizer(e['text'], truncation=True, padding='max_length', max_length=MAX_LENGTH), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27f429c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T04:02:33.985429Z",
     "start_time": "2021-06-20T04:02:33.980943Z"
    }
   },
   "outputs": [],
   "source": [
    "# 为了放进pytorch模型训练，还要再声明格式和使用的字段\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "dev_dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63ba2ddb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T04:02:40.812920Z",
     "start_time": "2021-06-20T04:02:40.808667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'label': ClassLabel(num_classes=4, names=['World', 'Sports', 'Business', 'Sci/Tech'], names_file=None, id=None),\n",
       " 'labels': Value(dtype='int64', id=None),\n",
       " 'text': Value(dtype='string', id=None),\n",
       " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c554ea9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T04:02:56.242472Z",
     "start_time": "2021-06-20T04:02:56.197354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'input_ids': tensor([  101,  2813,  2358,  1012,  6468, 15020,  2067,  2046,  1996,  2304,\n",
       "          1006, 26665,  1007, 26665,  1011,  2460,  1011, 19041,  1010,  2813,\n",
       "          2395,  1005,  1055,  1040, 11101,  2989,  1032,  2316,  1997, 11087,\n",
       "          1011, 22330,  8713,  2015,  1010,  2024,  3773,  2665,  2153,  1012,\n",
       "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]),\n",
       " 'labels': tensor(2),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7732f4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T04:25:46.523162Z",
     "start_time": "2021-06-20T04:25:46.519391Z"
    }
   },
   "outputs": [],
   "source": [
    "# 指定模型训练时，显示的验证指标\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10585b62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T05:18:36.563503Z",
     "start_time": "2021-06-20T04:27:29.416159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 51:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.280700</td>\n",
       "      <td>0.311167</td>\n",
       "      <td>0.896400</td>\n",
       "      <td>0.897377</td>\n",
       "      <td>0.900655</td>\n",
       "      <td>0.897665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.207000</td>\n",
       "      <td>0.295274</td>\n",
       "      <td>0.901000</td>\n",
       "      <td>0.902113</td>\n",
       "      <td>0.903560</td>\n",
       "      <td>0.902292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.317574</td>\n",
       "      <td>0.901200</td>\n",
       "      <td>0.902456</td>\n",
       "      <td>0.903191</td>\n",
       "      <td>0.902526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 指定训练参数，使用trainer直接训练\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    learning_rate=3e-4,\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=64,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=100,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    no_cuda=False,\n",
    "    load_best_model_at_end=True,\n",
    "    # eval_steps=100,\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=dev_dataset,            # evaluation dataset\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "train_out = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f438feea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T05:50:41.802648Z",
     "start_time": "2021-06-20T05:50:41.792598Z"
    }
   },
   "outputs": [],
   "source": [
    "# 使用pipeline直接对文本进行预测\n",
    "# pipeline可以直接加载训练好的模型和tokenizer，然后直接对文本进行分类预测，无需再自行预处理\n",
    "\n",
    "# 我们把模型放回cpu来进行预测\n",
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f56c3e4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T05:50:44.369689Z",
     "start_time": "2021-06-20T05:50:44.365976Z"
    }
   },
   "outputs": [],
   "source": [
    "# 用sentiment-analysis来指定我们做的是文本分类任务（情感分析是一类代表性的文本分类任务），并指定我们之前训好的模型。\n",
    "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ef7bff0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T05:50:49.473393Z",
     "start_time": "2021-06-20T05:50:46.057728Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/Users/lhj/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 2,\n",
       " 'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\"}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_examples = load_dataset(\"ag_news\", split=\"test[:10]\")\n",
    "test_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cc9ef49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T05:50:53.244518Z",
     "start_time": "2021-06-20T05:50:53.226194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_2', 'score': 0.9229997396469116}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = classifier(test_examples[0]['text'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457861ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
